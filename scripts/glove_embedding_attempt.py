# -*- coding: utf-8 -*-
"""GloVe Embedding Attempt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZjMNIzJmWBZWulGXF8VTEsNV5dnrLiV_
"""

!pip install -q pyLDAvis

import matplotlib.pyplot as plt
import numpy as np
import os
import operator
from nltk.corpus import stopwords
import gensim
from gensim import corpora, models
# from textblob import TextBlob
from bs4 import BeautifulSoup
import pyLDAvis.gensim_models 
import pickle 
import pyLDAvis
import tqdm

import nltk
from nltk.stem import WordNetLemmatizer
  
lemmatizer = WordNetLemmatizer()
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('omw-1.4')

from nltk.corpus import stopwords
import spacy
from spacy import displacy
from collections import Counter
import en_core_web_sm
nlp = en_core_web_sm.load()
import spacy
#loading the english language small model of spacy
en = spacy.load('en_core_web_sm')
sw_spacy = en.Defaults.stop_words
print(sw_spacy)

def preprocess(email):
  tokens = nltk.word_tokenize(email)
  l_nouns = [lemmatizer.lemmatize(word) for word in tokens]
  non_stop = []
  for entry in l_nouns:
    if((entry not in stopwords.words('english')) and (entry not in sw_spacy) and (entry.isalnum()) and len(entry)>2):
      non_stop.append(entry)
  l_nouns = [word.lower() for word in non_stop]
  nouns = ' '.join(l_nouns)
  doc = nlp(nouns)
  nouns = [doc[i] for i in range(len(doc)) if doc[i].tag_ == 'NN' or doc[i].tag_ == 'NNS']
  nouns = [str(noun) for noun in nouns]
  return nouns

#@title
def preprocess_mail(filename):
  with open(filename,'r') as f:
    text = f.read()
  return preprocess(text)

from google.colab import drive
drive.mount('/content/drive')

"""#Word2Vec

"""

def word2vec(word):
    from collections import Counter
    from math import sqrt

    # count the characters in word
    cw = Counter(word)
    # precomputes a set of the different characters
    sw = set(cw)
    # precomputes the "length" of the word vector
    lw = sqrt(sum(c*c for c in cw.values()))

    # return a tuple
    return cw, sw, lw

def cosdis(v1, v2):
    # which characters are common to the two words?
    common = v1[1].intersection(v2[1])
    # by definition of cosine distance we have
    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]



def list_comp(list_A,list_B):
  threshold = 0.80     # if needed
  sum = 0
  count = 0
  for key in list_A:
    for word in list_B:
        try:
            # print(key)
            # print(word)
            res = cosdis(word2vec(word), word2vec(key))
            sum += res
            count += 1
            # print(res)
            print("The cosine similarity between : {} and : {} is: {}".format(word, key, res*100))
            # if res > threshold:
            #     print("Found a word with cosine distance > 80 : {} with original word: {}".format(word, key))
        except IndexError:
            pass
  return sum/count

tokenized_sent = [preprocess_mail('text1.txt'),preprocess_mail('text1s.txt'),preprocess_mail('text2.txt'),preprocess_mail('text3.txt')]

from gensim.models.doc2vec import Doc2Vec, TaggedDocument
tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_sent)]
tagged_data

model = Doc2Vec(tagged_data, vector_size = 20, window = 2, min_count = 1, epochs = 100)

'''
vector_size = Dimensionality of the feature vectors.
window = The maximum distance between the current and predicted word within a sentence.
min_count = Ignores all words with total frequency lower than this.
alpha = The initial learning rate.
'''

## Print model vocabulary
model.wv.vocab

test_doc = preprocess_mail('texttest.txt')
test_doc_vector = model.infer_vector(test_doc)
model.docvecs.most_similar(positive = [test_doc_vector])

"""Data"""

#@title
tokenized_sent = [['palakkad',
  'placement',
  'institute',
  'kumar',
  'iit',
  'contact',
  'student',
  'technology',
  'internship',
  'training',
  'representative',
  'application',
  'officer',
  'deadline',
  'post',
  'cdc',
  'batch',
  'year',
  'candidate',
  'information',
  'coordinator',
  'test',
  'link',
  'interview',
  'sep',
  'scholarship',
  'indian',
  'career',
  'oct',
  'affairs',
  'process',
  'profile',
  'yagnesh',
  'job',
  'registration',
  'aug',
  'form',
  'development',
  'peer',
  'detail',
  'sac',
  'feel',
  'email',
  'mail',
  'thank',
  'election',
  'august',
  'head',
  'katragadda',
  'dear'],
 ['student',
  'innovation',
  'iit',
  'team',
  'message',
  'information',
  'india',
  'program',
  'palakkad',
  'technology',
  'challenge',
  'project',
  'opportunity',
  'nikhil',
  'year',
  'council',
  'session',
  'detail',
  'details',
  'idea',
  'event',
  'link',
  'industry',
  'problem',
  'help',
  'share',
  'college',
  'email',
  'business',
  'registration',
  'students',
  'application',
  'prize',
  'onbehalf',
  'support',
  'solution',
  'case',
  'behalf',
  'platform',
  'skill',
  'experience',
  'development',
  'product',
  'research',
  'work',
  'dear',
  'education',
  'speaker',
  'world',
  'school'],
 ['team',
  'sports',
  'singh',
  'event',
  'google',
  'time',
  'competition',
  'form',
  'petrichor',
  'email',
  'iit',
  'response',
  'invitation',
  'batch',
  'affairs',
  'video',
  'game',
  'account',
  'rituraj',
  'people',
  'jul',
  'yoga',
  'music',
  'list',
  'pm',
  'zoom',
  'hope',
  'thanks',
  'change',
  'activity',
  'hrishi',
  'meet',
  'raaj',
  'member',
  'guest',
  'tutorial',
  'fitness',
  'link',
  'greetings',
  'college',
  'day',
  'dec',
  'organizer',
  'secretary',
  'club',
  'join',
  'manoranjan',
  'player',
  'fill',
  'room'],
 ['institute',
  'indian',
  'technology',
  'engineering',
  'palakkad',
  'iit',
  'professor',
  'research',
  'assistant',
  'science',
  'department',
  'associate',
  'talk',
  'computer',
  'kerala',
  'india',
  'ahalia',
  'faculty',
  'university',
  'data',
  'systems',
  'sunil',
  'vinod',
  'national',
  'ieee',
  'conference',
  'dean',
  'thanks',
  'mechanical',
  'director',
  'kumar',
  'chemistry',
  'uma',
  'lecture',
  'paper',
  'centre',
  'detail',
  'meeting',
  'transit',
  'academy',
  'machine',
  'series',
  'room',
  'prasad',
  'phd',
  'kozhippara',
  'patient',
  'colloquium',
  'sushabhan',
  'award'],
 ['answer',
  'min',
  'people',
  'time',
  'thing',
  'type',
  'control',
  'read',
  'year',
  'word',
  'day',
  'campus',
  'language',
  'life',
  'world',
  'way',
  'email',
  'body',
  'sandhya',
  'friend',
  'work',
  'person',
  'stories',
  'point',
  'movie',
  'use',
  'money',
  'support',
  'mind',
  'data',
  'english',
  'jee',
  'love',
  'question',
  'chandran',
  'business',
  'sanjay',
  'sentence',
  'article',
  'help',
  'fact',
  'services',
  'place',
  'verb',
  'experience',
  'lot',
  'practice',
  'job',
  'woman',
  'end'],
 ['class',
  'forum',
  'change',
  'lab',
  'assignment',
  'digest',
  'forums',
  'course',
  'question',
  'exam',
  'quiz',
  'lecture',
  'dear',
  'time',
  'announcements',
  'week',
  'submission',
  'video',
  'student',
  'note',
  'link',
  'problem',
  'book',
  'meeting',
  'mark',
  'today',
  'zoom',
  'evaluation',
  'tomorrow',
  'november',
  'feedback',
  'answer',
  'number',
  'end',
  'test',
  'semester',
  'batch',
  'discussion',
  'hope',
  'nov',
  'october',
  'code',
  'sheet',
  'solution',
  'library',
  'message',
  'unsubscribe',
  'grade',
  'moodle',
  'file'],
 ['research',
  'meeting',
  'seminar',
  'system',
  'zoom',
  'proposal',
  'analysis',
  'detail',
  'work',
  'design',
  'study',
  'material',
  'model',
  'method',
  'iit',
  'talk',
  'performance',
  'view',
  'office',
  'data',
  'time',
  'quantum',
  'palakkad',
  'technique',
  'link',
  'power',
  'email',
  'vehicle',
  'graph',
  'application',
  'structure',
  'control',
  'number',
  'algorithm',
  'date',
  'space',
  'dean',
  'problem',
  'network',
  'process',
  'systems',
  'presentation',
  'stress',
  'reminder',
  'contact',
  'adobe',
  'energy',
  'detection',
  'effect',
  'hpc'],
 ['session',
  'iit',
  'link',
  'club',
  'palakkad',
  'form',
  'workshop',
  'contact',
  'thanks',
  'event',
  'google',
  'detail',
  'competition',
  'follow',
  'meeting',
  'alumni',
  'student',
  'affairs',
  'hope',
  'registration',
  'technical',
  'secretary',
  'arts',
  'logo',
  'deadline',
  'mohit',
  'entry',
  'programming',
  'team',
  'paper',
  'cell',
  'webinar',
  'head',
  'point',
  'mail',
  'contest',
  'member',
  'quiz',
  'talk',
  'participation',
  'opportunity',
  'reminder',
  'training',
  'time',
  'robotics',
  'introduction',
  'design',
  'fill',
  'san',
  'september'],
 ['student',
  'institute',
  'palakkad',
  'campus',
  'affairs',
  'ahalia',
  'indian',
  'hostel',
  'technology',
  'secretary',
  'form',
  'iit',
  'nila',
  'thanks',
  'day',
  'council',
  'students',
  'dean',
  'general',
  'registrar',
  'time',
  'staff',
  'semester',
  'mess',
  'fill',
  'faculty',
  'course',
  'fee',
  'contact',
  'number',
  'registration',
  'academics',
  'yaseen',
  'request',
  'room',
  'case',
  'date',
  'office',
  'mail',
  'person',
  'service',
  'bus',
  'dear',
  'google',
  'academic',
  'payment',
  'kozhippara',
  'year',
  'batch',
  'aug'],
 ['internship',
  'biju',
  'campus',
  'inr',
  'joel',
  'kerala',
  'ahalia',
  'dist',
  'kozhippara',
  'development',
  'sam',
  'thanks',
  'mathew',
  'vivek',
  'officer',
  'palakkad',
  'iit',
  'jan',
  'start',
  'technical',
  'computer',
  'mar',
  'work',
  'chaturvedi',
  'service',
  'matlab',
  'apr',
  'attendance',
  'internet',
  'gaming',
  'inconvenience',
  'software',
  'jun',
  'team',
  'email',
  'john',
  'company',
  'situation',
  'lab',
  'solutions',
  'connectivity',
  'jerry',
  'feb',
  'list',
  'thomas',
  'dear',
  'design',
  'download',
  'nov',
  'app'],
 ['course',
  'anoop',
  'email',
  'george',
  'coursera',
  'university',
  'iit',
  'google',
  'social',
  'sciences',
  'department',
  'palakkad',
  'humanities',
  'nptel',
  'kerala',
  'unsubscribe',
  'view',
  'group',
  'learning',
  'web',
  'summary',
  'specialization',
  'machine',
  'oct',
  'data',
  'dec',
  'visit',
  'groups',
  'regard',
  'discussion',
  'topic',
  'message',
  'science',
  'trademark',
  'class',
  'lecture',
  'introduction',
  'certificate',
  'aug',
  'python',
  'learner',
  'ibm',
  'dear',
  'ethics',
  'thanks',
  'today',
  'enroll',
  'help',
  'language',
  'time']]

from gensim.models.doc2vec import Doc2Vec, TaggedDocument
tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_sent)]
tagged_data

model2 = Doc2Vec(tagged_data, vector_size = 20, window = 2, min_count = 1, epochs = 100)
model.wv.vocab

test_doc = preprocess_mail('texttest.txt')
test_doc_vector = model.infer_vector(test_doc)
model2.docvecs.most_similar(positive = [test_doc_vector])



"""#Glove"""

import os
import urllib.request
import matplotlib.pyplot as plt
from scipy import spatial
from sklearn.manifold import TSNE
import numpy as np

urllib.request.urlretrieve('https://nlp.stanford.edu/data/glove.6B.zip','glove.6B.zip')

!unzip "/content/glove.6B.zip" -d "/content/"

gdim = 200 # Glove Dimension

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np
from numpy.linalg import norm
import tensorflow as tf
import torch
import torchtext

# The first time you run this will download a ~823MB file
glove = torchtext.vocab.GloVe(name="6B", # trained on Wikipedia 2014 corpus
                              dim=gdim)    # embedding size = 50

"""###Data in list (all_topics)
No need to see

"""

#@title
all_topics = [['palakkad',
  'placement',
  'institute',
  'kumar',
  'iit',
  'contact',
  'student',
  'technology',
  'internship',
  'training',
  'representative',
  'application',
  'officer',
  'deadline',
  'post',
  'cdc',
  'batch',
  'year',
  'candidate',
  'information',
  'coordinator',
  'test',
  'link',
  'interview',
  'sep',
  'scholarship',
  'indian',
  'career',
  'oct',
  'affairs',
  'process',
  'profile',
  'yagnesh',
  'job',
  'registration',
  'aug',
  'form',
  'development',
  'peer',
  'detail',
  'sac',
  'feel',
  'email',
  'mail',
  'thank',
  'election',
  'august',
  'head',
  'katragadda',
  'dear'],
 ['student',
  'innovation',
  'iit',
  'team',
  'message',
  'information',
  'india',
  'program',
  'palakkad',
  'technology',
  'challenge',
  'project',
  'opportunity',
  'nikhil',
  'year',
  'council',
  'session',
  'detail',
  'details',
  'idea',
  'event',
  'link',
  'industry',
  'problem',
  'help',
  'share',
  'college',
  'email',
  'business',
  'registration',
  'students',
  'application',
  'prize',
  'onbehalf',
  'support',
  'solution',
  'case',
  'behalf',
  'platform',
  'skill',
  'experience',
  'development',
  'product',
  'research',
  'work',
  'dear',
  'education',
  'speaker',
  'world',
  'school'],
 ['team',
  'sports',
  'singh',
  'event',
  'google',
  'time',
  'competition',
  'form',
  'petrichor',
  'email',
  'iit',
  'response',
  'invitation',
  'batch',
  'affairs',
  'video',
  'game',
  'account',
  'rituraj',
  'people',
  'jul',
  'yoga',
  'music',
  'list',
  'pm',
  'zoom',
  'hope',
  'thanks',
  'change',
  'activity',
  'hrishi',
  'meet',
  'raaj',
  'member',
  'guest',
  'tutorial',
  'fitness',
  'link',
  'greetings',
  'college',
  'day',
  'dec',
  'organizer',
  'secretary',
  'club',
  'join',
  'manoranjan',
  'player',
  'fill',
  'room'],
 ['institute',
  'indian',
  'technology',
  'engineering',
  'palakkad',
  'iit',
  'professor',
  'research',
  'assistant',
  'science',
  'department',
  'associate',
  'talk',
  'computer',
  'kerala',
  'india',
  'ahalia',
  'faculty',
  'university',
  'data',
  'systems',
  'sunil',
  'vinod',
  'national',
  'ieee',
  'conference',
  'dean',
  'thanks',
  'mechanical',
  'director',
  'kumar',
  'chemistry',
  'uma',
  'lecture',
  'paper',
  'centre',
  'detail',
  'meeting',
  'transit',
  'academy',
  'machine',
  'series',
  'room',
  'prasad',
  'phd',
  'kozhippara',
  'patient',
  'colloquium',
  'sushabhan',
  'award'],
 ['answer',
  'min',
  'people',
  'time',
  'thing',
  'type',
  'control',
  'read',
  'year',
  'word',
  'day',
  'campus',
  'language',
  'life',
  'world',
  'way',
  'email',
  'body',
  'sandhya',
  'friend',
  'work',
  'person',
  'stories',
  'point',
  'movie',
  'use',
  'money',
  'support',
  'mind',
  'data',
  'english',
  'jee',
  'love',
  'question',
  'chandran',
  'business',
  'sanjay',
  'sentence',
  'article',
  'help',
  'fact',
  'services',
  'place',
  'verb',
  'experience',
  'lot',
  'practice',
  'job',
  'woman',
  'end'],
 ['class',
  'forum',
  'change',
  'lab',
  'assignment',
  'digest',
  'forums',
  'course',
  'question',
  'exam',
  'quiz',
  'lecture',
  'dear',
  'time',
  'announcements',
  'week',
  'submission',
  'video',
  'student',
  'note',
  'link',
  'problem',
  'book',
  'meeting',
  'mark',
  'today',
  'zoom',
  'evaluation',
  'tomorrow',
  'november',
  'feedback',
  'answer',
  'number',
  'end',
  'test',
  'semester',
  'batch',
  'discussion',
  'hope',
  'nov',
  'october',
  'code',
  'sheet',
  'solution',
  'library',
  'message',
  'unsubscribe',
  'grade',
  'moodle',
  'file'],
 ['research',
  'meeting',
  'seminar',
  'system',
  'zoom',
  'proposal',
  'analysis',
  'detail',
  'work',
  'design',
  'study',
  'material',
  'model',
  'method',
  'iit',
  'talk',
  'performance',
  'view',
  'office',
  'data',
  'time',
  'quantum',
  'palakkad',
  'technique',
  'link',
  'power',
  'email',
  'vehicle',
  'graph',
  'application',
  'structure',
  'control',
  'number',
  'algorithm',
  'date',
  'space',
  'dean',
  'problem',
  'network',
  'process',
  'systems',
  'presentation',
  'stress',
  'reminder',
  'contact',
  'adobe',
  'energy',
  'detection',
  'effect',
  'hpc'],
 ['session',
  'iit',
  'link',
  'club',
  'palakkad',
  'form',
  'workshop',
  'contact',
  'thanks',
  'event',
  'google',
  'detail',
  'competition',
  'follow',
  'meeting',
  'alumni',
  'student',
  'affairs',
  'hope',
  'registration',
  'technical',
  'secretary',
  'arts',
  'logo',
  'deadline',
  'mohit',
  'entry',
  'programming',
  'team',
  'paper',
  'cell',
  'webinar',
  'head',
  'point',
  'mail',
  'contest',
  'member',
  'quiz',
  'talk',
  'participation',
  'opportunity',
  'reminder',
  'training',
  'time',
  'robotics',
  'introduction',
  'design',
  'fill',
  'san',
  'september'],
 ['student',
  'institute',
  'palakkad',
  'campus',
  'affairs',
  'ahalia',
  'indian',
  'hostel',
  'technology',
  'secretary',
  'form',
  'iit',
  'nila',
  'thanks',
  'day',
  'council',
  'students',
  'dean',
  'general',
  'registrar',
  'time',
  'staff',
  'semester',
  'mess',
  'fill',
  'faculty',
  'course',
  'fee',
  'contact',
  'number',
  'registration',
  'academics',
  'yaseen',
  'request',
  'room',
  'case',
  'date',
  'office',
  'mail',
  'person',
  'service',
  'bus',
  'dear',
  'google',
  'academic',
  'payment',
  'kozhippara',
  'year',
  'batch',
  'aug'],
 ['internship',
  'biju',
  'campus',
  'inr',
  'joel',
  'kerala',
  'ahalia',
  'dist',
  'kozhippara',
  'development',
  'sam',
  'thanks',
  'mathew',
  'vivek',
  'officer',
  'palakkad',
  'iit',
  'jan',
  'start',
  'technical',
  'computer',
  'mar',
  'work',
  'chaturvedi',
  'service',
  'matlab',
  'apr',
  'attendance',
  'internet',
  'gaming',
  'inconvenience',
  'software',
  'jun',
  'team',
  'email',
  'john',
  'company',
  'situation',
  'lab',
  'solutions',
  'connectivity',
  'jerry',
  'feb',
  'list',
  'thomas',
  'dear',
  'design',
  'download',
  'nov',
  'app'],
 ['course',
  'anoop',
  'email',
  'george',
  'coursera',
  'university',
  'iit',
  'google',
  'social',
  'sciences',
  'department',
  'palakkad',
  'humanities',
  'nptel',
  'kerala',
  'unsubscribe',
  'view',
  'group',
  'learning',
  'web',
  'summary',
  'specialization',
  'machine',
  'oct',
  'data',
  'dec',
  'visit',
  'groups',
  'regard',
  'discussion',
  'topic',
  'message',
  'science',
  'trademark',
  'class',
  'lecture',
  'introduction',
  'certificate',
  'aug',
  'python',
  'learner',
  'ibm',
  'dear',
  'ethics',
  'thanks',
  'today',
  'enroll',
  'help',
  'language',
  'time']]

def cos_similarity(filename):
  x_test = preprocess_mail(filename)
  cos = []
  u = avg_embedding(x_test)
  for listing in all_topics:
    v = avg_embedding(listing)
    cosine = np.dot(u,v)/(norm(u)*norm(v))
    cos.append(cosine)
  print(cos)
  topic = cos.index(max(cos))
  print(topic)
  wcos = []
  for word in all_topics[topic][:10]:
    lis = []
    lis.append(word)
    v = avg_embedding(lis)
    cosine = np.dot(u,v)/(norm(u)*norm(v))
    wcos.append(cosine)
  return all_topics[topic][wcos.index(max(wcos))]
  # wcos = {}
  # for topic in all_topics:
  #   for i in range(10):
  #     lis = []
  #     lis.append(topic[i])
  #     v = avg_embedding(lis)
  #     cosine = np.dot(u,v)/(norm(u)*norm(v))
  #     wcos[topic[i]] = cosine
  # return wcos

cos_similarity('text1.txt')

cos_similarity('text2.txt')

cos_similarity('text3.txt')

"""#Glove with Changed probabilities

##Data
"""

Tags_prob = {0: {'placement': 0.03,
  'representative': 0.013,
  'kumar': 0.0105,
  'post': 0.01,
  'cdc': 0.01,
  'institute': 0.009333333333333334,
  'candidate': 0.009,
  'coordinator': 0.008,
  'internship': 0.007,
  'training': 0.007,
  'interview': 0.007,
  'sep': 0.007,
  'scholarship': 0.007,
  'career': 0.007,
  'profile': 0.006,
  'yagnesh': 0.006,
  'officer': 0.0055,
  'deadline': 0.005,
  'peer': 0.005,
  'sac': 0.005,
  'feel': 0.005,
  'thank': 0.005,
  'contact': 0.0045,
  'information': 0.0045,
  'palakkad': 0.00425,
  'technology': 0.004,
  'test': 0.004,
  'election': 0.004,
  'august': 0.004,
  'katragadda': 0.004,
  'application': 0.0036666666666666666,
  'oct': 0.0035,
  'process': 0.0035,
  'student': 0.0034000000000000002,
  'job': 0.003,
  'indian': 0.0023333333333333335,
  'batch': 0.00225,
  'year': 0.00225,
  'iit': 0.0022222222222222222,
  'aug': 0.002,
  'head': 0.002,
  'affairs': 0.00175,
  'development': 0.0016666666666666668,
  'mail': 0.0016666666666666668,
  'registration': 0.0015,
  'form': 0.00125,
  'link': 0.0011666666666666668,
  'detail': 0.001,
  'email': 0.0007142857142857143,
  'dear': 0.0006666666666666666},
 1: {'innovation': 0.019,
  'program': 0.009,
  'challenge': 0.008,
  'project': 0.008,
  'nikhil': 0.007,
  'information': 0.006,
  'details': 0.006,
  'idea': 0.006,
  'india': 0.005,
  'industry': 0.005,
  'share': 0.005,
  'student': 0.0048000000000000004,
  'message': 0.004333333333333333,
  'opportunity': 0.004,
  'prize': 0.004,
  'onbehalf': 0.004,
  'council': 0.0035,
  'team': 0.00325,
  'session': 0.003,
  'behalf': 0.003,
  'platform': 0.003,
  'skill': 0.003,
  'product': 0.003,
  'education': 0.003,
  'speaker': 0.003,
  'school': 0.003,
  'iit': 0.002,
  'technology': 0.002,
  'event': 0.002,
  'college': 0.002,
  'business': 0.002,
  'students': 0.002,
  'support': 0.002,
  'solution': 0.002,
  'year': 0.00175,
  'problem': 0.0016666666666666668,
  'help': 0.0016666666666666668,
  'case': 0.0015,
  'experience': 0.0015,
  'world': 0.0015,
  'application': 0.0013333333333333333,
  'detail': 0.0012000000000000001,
  'palakkad': 0.001,
  'registration': 0.001,
  'development': 0.001,
  'research': 0.001,
  'link': 0.0008333333333333334,
  'work': 0.00075,
  'email': 0.0005714285714285715,
  'dear': 0.0005},
 2: {'sports': 0.019,
  'singh': 0.019,
  'petrichor': 0.009,
  'response': 0.009,
  'invitation': 0.009,
  'game': 0.007,
  'account': 0.007,
  'team': 0.006,
  'competition': 0.006,
  'rituraj': 0.006,
  'jul': 0.006,
  'yoga': 0.006,
  'music': 0.006,
  'pm': 0.006,
  'event': 0.005999999999999999,
  'activity': 0.005,
  'hrishi': 0.005,
  'meet': 0.005,
  'raaj': 0.005,
  'guest': 0.005,
  'tutorial': 0.005,
  'fitness': 0.005,
  'greetings': 0.005,
  'google': 0.004,
  'organizer': 0.004,
  'join': 0.004,
  'manoranjan': 0.004,
  'player': 0.004,
  'video': 0.0035,
  'people': 0.003,
  'list': 0.003,
  'form': 0.00275,
  'change': 0.0025,
  'member': 0.0025,
  'college': 0.002,
  'dec': 0.002,
  'club': 0.002,
  'time': 0.0018571428571428571,
  'batch': 0.00175,
  'affairs': 0.00175,
  'zoom': 0.0016666666666666668,
  'hope': 0.0016666666666666668,
  'day': 0.0013333333333333333,
  'secretary': 0.0013333333333333333,
  'fill': 0.0013333333333333333,
  'room': 0.0013333333333333333,
  'email': 0.0012857142857142856,
  'iit': 0.001,
  'thanks': 0.0008333333333333334,
  'link': 0.0008333333333333334},
 3: {'engineering': 0.026,
  'professor': 0.022,
  'assistant': 0.019,
  'institute': 0.012333333333333333,
  'associate': 0.011,
  'indian': 0.009666666666666667,
  'science': 0.0085,
  'technology': 0.00675,
  'research': 0.006666666666666667,
  'department': 0.006,
  'computer': 0.005,
  'sunil': 0.005,
  'vinod': 0.005,
  'national': 0.005,
  'ieee': 0.005,
  'conference': 0.005,
  'mechanical': 0.005,
  'director': 0.005,
  'chemistry': 0.005,
  'india': 0.0045,
  'uma': 0.004,
  'centre': 0.004,
  'transit': 0.004,
  'academy': 0.004,
  'talk': 0.0036666666666666666,
  'kerala': 0.0033333333333333335,
  'palakkad': 0.003125,
  'faculty': 0.003,
  'university': 0.003,
  'series': 0.003,
  'prasad': 0.003,
  'phd': 0.003,
  'patient': 0.003,
  'colloquium': 0.003,
  'sushabhan': 0.003,
  'award': 0.003,
  'iit': 0.0026666666666666666,
  'systems': 0.0025,
  'kumar': 0.0025,
  'ahalia': 0.0023333333333333335,
  'paper': 0.002,
  'machine': 0.002,
  'dean': 0.0016666666666666668,
  'data': 0.0015,
  'lecture': 0.0013333333333333333,
  'meeting': 0.001,
  'room': 0.001,
  'kozhippara': 0.001,
  'thanks': 0.0008333333333333334,
  'detail': 0.0008},
 4: {'answer': 0.014,
  'min': 0.014,
  'thing': 0.01,
  'type': 0.01,
  'read': 0.009,
  'word': 0.008,
  'life': 0.007,
  'way': 0.006,
  'body': 0.006,
  'people': 0.0055,
  'sandhya': 0.005,
  'friend': 0.005,
  'control': 0.0045,
  'stories': 0.004,
  'movie': 0.004,
  'use': 0.004,
  'money': 0.004,
  'language': 0.0035,
  'world': 0.0035,
  'mind': 0.003,
  'english': 0.003,
  'jee': 0.003,
  'love': 0.003,
  'chandran': 0.003,
  'sanjay': 0.003,
  'sentence': 0.003,
  'article': 0.003,
  'fact': 0.003,
  'services': 0.003,
  'place': 0.003,
  'verb': 0.003,
  'person': 0.0025,
  'day': 0.0023333333333333335,
  'campus': 0.0023333333333333335,
  'year': 0.002,
  'point': 0.002,
  'support': 0.002,
  'lot': 0.002,
  'practice': 0.002,
  'woman': 0.002,
  'question': 0.0015,
  'business': 0.0015,
  'time': 0.0014285714285714286,
  'work': 0.00125,
  'help': 0.001,
  'experience': 0.001,
  'job': 0.001,
  'end': 0.001,
  'email': 0.0008571428571428572,
  'data': 0.00075},
 5: {'forum': 0.022,
  'assignment': 0.018,
  'digest': 0.017,
  'forums': 0.016,
  'class': 0.0145,
  'exam': 0.014,
  'change': 0.01,
  'announcements': 0.01,
  'lab': 0.0095,
  'week': 0.009,
  'submission': 0.009,
  'note': 0.008,
  'book': 0.008,
  'question': 0.0075,
  'mark': 0.007,
  'quiz': 0.0065,
  'evaluation': 0.006,
  'course': 0.005333333333333333,
  'tomorrow': 0.005,
  'november': 0.005,
  'feedback': 0.005,
  'video': 0.0045,
  'lecture': 0.004333333333333333,
  'october': 0.004,
  'code': 0.004,
  'sheet': 0.004,
  'library': 0.004,
  'grade': 0.004,
  'moodle': 0.004,
  'file': 0.004,
  'today': 0.0035,
  'problem': 0.0026666666666666666,
  'answer': 0.0025,
  'end': 0.0025,
  'test': 0.0025,
  'semester': 0.0025,
  'dear': 0.0021666666666666666,
  'zoom': 0.002,
  'discussion': 0.002,
  'nov': 0.002,
  'solution': 0.002,
  'unsubscribe': 0.002,
  'student': 0.0018,
  'meeting': 0.00175,
  'time': 0.0017142857142857144,
  'number': 0.0016666666666666668,
  'link': 0.0013333333333333333,
  'hope': 0.0013333333333333333,
  'message': 0.0013333333333333333,
  'batch': 0.00125},
 6: {'seminar': 0.011,
  'system': 0.01,
  'research': 0.009,
  'proposal': 0.009,
  'analysis': 0.009,
  'study': 0.008,
  'material': 0.007,
  'model': 0.006,
  'method': 0.006,
  'performance': 0.006,
  'quantum': 0.005,
  'technique': 0.005,
  'power': 0.005,
  'vehicle': 0.004,
  'graph': 0.004,
  'structure': 0.004,
  'algorithm': 0.004,
  'space': 0.004,
  'network': 0.004,
  'presentation': 0.004,
  'stress': 0.004,
  'meeting': 0.00325,
  'adobe': 0.003,
  'energy': 0.003,
  'detection': 0.003,
  'effect': 0.003,
  'hpc': 0.003,
  'zoom': 0.0029999999999999996,
  'design': 0.0026666666666666666,
  'view': 0.0025,
  'office': 0.0025,
  'work': 0.002,
  'talk': 0.002,
  'control': 0.002,
  'date': 0.002,
  'process': 0.002,
  'systems': 0.002,
  'detail': 0.0018,
  'reminder': 0.0015,
  'application': 0.0013333333333333333,
  'number': 0.0013333333333333333,
  'dean': 0.0013333333333333333,
  'problem': 0.0013333333333333333,
  'data': 0.00125,
  'link': 0.0008333333333333334,
  'contact': 0.00075,
  'time': 0.0007142857142857143,
  'email': 0.0007142857142857143,
  'iit': 0.0006666666666666666,
  'palakkad': 0.000625},
 7: {'session': 0.031,
  'workshop': 0.012,
  'club': 0.011,
  'follow': 0.008,
  'alumni': 0.007,
  'link': 0.005333333333333333,
  'arts': 0.005,
  'logo': 0.005,
  'mohit': 0.005,
  'entry': 0.005,
  'programming': 0.005,
  'cell': 0.005,
  'webinar': 0.005,
  'competition': 0.004,
  'contest': 0.004,
  'participation': 0.004,
  'robotics': 0.004,
  'iit': 0.0035555555555555557,
  'event': 0.0033333333333333335,
  'form': 0.00325,
  'contact': 0.003,
  'san': 0.003,
  'september': 0.003,
  'technical': 0.0025,
  'deadline': 0.0025,
  'paper': 0.0025,
  'palakkad': 0.002375,
  'google': 0.00225,
  'meeting': 0.002,
  'hope': 0.002,
  'head': 0.002,
  'point': 0.002,
  'member': 0.002,
  'quiz': 0.002,
  'opportunity': 0.002,
  'reminder': 0.002,
  'training': 0.002,
  'introduction': 0.002,
  'thanks': 0.0018333333333333333,
  'detail': 0.0018,
  'secretary': 0.0016666666666666668,
  'affairs': 0.0015,
  'student': 0.0014,
  'mail': 0.0013333333333333333,
  'talk': 0.0013333333333333333,
  'design': 0.0013333333333333333,
  'fill': 0.0013333333333333333,
  'registration': 0.00125,
  'team': 0.00125,
  'time': 0.0005714285714285715},
 8: {'hostel': 0.018,
  'nila': 0.013,
  'institute': 0.01,
  'student': 0.008400000000000001,
  'campus': 0.008333333333333333,
  'general': 0.007,
  'ahalia': 0.006333333333333333,
  'registrar': 0.006,
  'staff': 0.006,
  'mess': 0.006,
  'fee': 0.006,
  'indian': 0.005999999999999999,
  'affairs': 0.00575,
  'secretary': 0.005333333333333333,
  'academics': 0.005,
  'yaseen': 0.005,
  'request': 0.005,
  'council': 0.0045,
  'technology': 0.004,
  'bus': 0.004,
  'academic': 0.004,
  'payment': 0.004,
  'palakkad': 0.003625,
  'form': 0.0035,
  'students': 0.0035,
  'semester': 0.003,
  'faculty': 0.003,
  'day': 0.0029999999999999996,
  'dean': 0.0023333333333333335,
  'thanks': 0.002,
  'fill': 0.002,
  'course': 0.002,
  'case': 0.002,
  'date': 0.002,
  'office': 0.002,
  'person': 0.002,
  'service': 0.002,
  'number': 0.0016666666666666668,
  'room': 0.0016666666666666668,
  'iit': 0.0014444444444444444,
  'mail': 0.0013333333333333333,
  'kozhippara': 0.0013333333333333333,
  'contact': 0.00125,
  'registration': 0.00125,
  'google': 0.001,
  'year': 0.001,
  'aug': 0.001,
  'time': 0.0008571428571428572,
  'batch': 0.00075,
  'dear': 0.0006666666666666666},
 9: {'biju': 0.028,
  'inr': 0.023,
  'joel': 0.019,
  'dist': 0.017,
  'sam': 0.016,
  'internship': 0.015,
  'mathew': 0.013,
  'vivek': 0.013,
  'jan': 0.012,
  'start': 0.01,
  'mar': 0.01,
  'chaturvedi': 0.009,
  'campus': 0.008333333333333333,
  'matlab': 0.008,
  'apr': 0.007,
  'attendance': 0.007,
  'internet': 0.007,
  'officer': 0.0065,
  'kerala': 0.006333333333333333,
  'ahalia': 0.006333333333333333,
  'gaming': 0.006,
  'inconvenience': 0.006,
  'software': 0.006,
  'jun': 0.006,
  'john': 0.006,
  'kozhippara': 0.005666666666666667,
  'development': 0.005666666666666667,
  'technical': 0.005,
  'computer': 0.005,
  'company': 0.005,
  'situation': 0.005,
  'solutions': 0.005,
  'connectivity': 0.005,
  'service': 0.004,
  'jerry': 0.004,
  'feb': 0.004,
  'thomas': 0.004,
  'download': 0.004,
  'app': 0.004,
  'thanks': 0.0025,
  'lab': 0.0025,
  'work': 0.00225,
  'list': 0.002,
  'nov': 0.002,
  'palakkad': 0.0015,
  'team': 0.0015,
  'iit': 0.0013333333333333333,
  'design': 0.0013333333333333333,
  'email': 0.0008571428571428572,
  'dear': 0.0006666666666666666},
 10: {'anoop': 0.032,
  'george': 0.021,
  'coursera': 0.018,
  'course': 0.016999999999999998,
  'social': 0.013,
  'sciences': 0.013,
  'humanities': 0.012,
  'nptel': 0.012,
  'group': 0.011,
  'learning': 0.01,
  'university': 0.009,
  'web': 0.009,
  'summary': 0.009,
  'specialization': 0.009,
  'visit': 0.008,
  'groups': 0.007,
  'department': 0.0065,
  'unsubscribe': 0.006,
  'regard': 0.006,
  'topic': 0.006,
  'view': 0.0055,
  'trademark': 0.005,
  'certificate': 0.005,
  'python': 0.005,
  'learner': 0.005,
  'ibm': 0.005,
  'machine': 0.0045,
  'kerala': 0.004,
  'oct': 0.004,
  'dec': 0.004,
  'ethics': 0.004,
  'enroll': 0.004,
  'google': 0.0035,
  'email': 0.0032857142857142855,
  'discussion': 0.003,
  'science': 0.0025,
  'class': 0.0025,
  'introduction': 0.0025,
  'data': 0.002,
  'message': 0.002,
  'today': 0.002,
  'language': 0.002,
  'iit': 0.0017777777777777779,
  'lecture': 0.0016666666666666668,
  'aug': 0.0016666666666666668,
  'palakkad': 0.0015,
  'help': 0.0013333333333333333,
  'dear': 0.0006666666666666666,
  'thanks': 0.0006666666666666666,
  'time': 0.0005714285714285715}}

"""##Most Recent Data"""

Tags_prob = {0: {'group': 0.062,
  'peer': 0.016,
  'computer': 0.016,
  'information': 0.0155,
  'service': 0.015,
  'visit': 0.015,
  'inconvenience': 0.013,
  'application': 0.011000000000000001,
  'movie': 0.011,
  'discussion': 0.009333333333333334,
  'view': 0.009333333333333334,
  'nptel': 0.009,
  'connectivity': 0.009,
  'letter': 0.008,
  'connection': 0.008,
  'duty': 0.008,
  'join': 0.0075,
  'message': 0.007,
  'profile': 0.007,
  'internet': 0.007,
  'auction': 0.007,
  'deadline': 0.006666666666666667,
  'contact': 0.0065,
  'test': 0.006,
  'trip': 0.006,
  'water': 0.006,
  'list': 0.005666666666666667,
  'lab': 0.005333333333333333,
  'parent': 0.005,
  'income': 0.005,
  'scholarship': 0.005,
  'scheme': 0.005,
  'verb': 0.005,
  'repeat': 0.005,
  'arm': 0.005,
  'process': 0.0045,
  'campus': 0.0045,
  'thanks': 0.004333333333333333,
  'circuit': 0.004,
  'interview': 0.004,
  'seat': 0.004,
  'document': 0.004,
  'failure': 0.004,
  'issue': 0.003,
  'use': 0.0026,
  'internship': 0.002,
  'coordinator': 0.002,
  'form': 0.00175,
  'series': 0.0016666666666666668,
  'today': 0.0015},
 1: {'team': 0.021,
  'post': 0.019,
  'form': 0.015,
  'club': 0.015,
  'competition': 0.0145,
  'event': 0.0145,
  'assignment': 0.012,
  'google': 0.01,
  'candidate': 0.01,
  'selection': 0.01,
  'game': 0.009,
  'sport': 0.009,
  'fill': 0.0085,
  'submission': 0.0075,
  'member': 0.007,
  'batch': 0.007,
  'player': 0.007,
  'election': 0.007,
  'response': 0.006,
  'secretary': 0.006,
  'status': 0.006,
  'winner': 0.006,
  'student': 0.005,
  'contact': 0.005,
  'activity': 0.005,
  'affair': 0.005,
  'position': 0.005,
  'feel': 0.005,
  'participant': 0.005,
  'nomination': 0.005,
  'vote': 0.005,
  'people': 0.0045,
  'participation': 0.0045,
  'tomorrow': 0.004,
  'query': 0.004,
  'deadline': 0.0036666666666666666,
  'section': 0.0035,
  'entry': 0.0035,
  'mail': 0.003,
  'point': 0.0026666666666666666,
  'date': 0.0025,
  'note': 0.0023333333333333335,
  'thanks': 0.0023333333333333335,
  'time': 0.00225,
  'year': 0.00225,
  'detail': 0.0021999999999999997,
  'case': 0.002,
  'number': 0.0013333333333333333,
  'help': 0.0012000000000000001,
  'request': 0.0012000000000000001},
 2: {'session': 0.068,
  'student': 0.0178,
  'inform': 0.016,
  'information': 0.0135,
  'event': 0.0115,
  'workshop': 0.011,
  'college': 0.009,
  'kind': 0.0085,
  'message': 0.008,
  'opportunity': 0.008,
  'behalf': 0.008,
  'program': 0.0075,
  'join': 0.007,
  'registration': 0.006,
  'poster': 0.006,
  'link': 0.00575,
  'edition': 0.005,
  'register': 0.0045,
  'institution': 0.004,
  'contest': 0.004,
  'conduct': 0.004,
  'chance': 0.004,
  'university': 0.004,
  'hour': 0.004,
  'year': 0.0035,
  'participation': 0.0035,
  'competition': 0.003,
  'talk': 0.003,
  'detail': 0.0028,
  'share': 0.0025,
  'application': 0.0023333333333333335,
  'series': 0.002,
  'platform': 0.002,
  'industry': 0.002,
  'regard': 0.002,
  'speaker': 0.002,
  'research': 0.0016666666666666668,
  'day': 0.0016666666666666668,
  'institute': 0.0016666666666666668,
  'mail': 0.0016,
  'date': 0.0015,
  'request': 0.0014,
  'meeting': 0.0013333333333333333,
  'discussion': 0.0013333333333333333,
  'contact': 0.00125,
  'faculty': 0.00125,
  'case': 0.00125,
  'help': 0.0012000000000000001,
  'email': 0.001,
  'time': 0.0005},
 3: {'project': 0.024,
  'innovation': 0.018,
  'technology': 0.018,
  'team': 0.013,
  'min': 0.01,
  'idea': 0.009,
  'data': 0.009,
  'product': 0.009,
  'support': 0.009,
  'network': 0.008,
  'business': 0.008,
  'solution': 0.007,
  'problem': 0.006333333333333333,
  'communication': 0.006,
  'area': 0.006,
  'machine': 0.006,
  'challenge': 0.005,
  'science': 0.005,
  'skill': 0.005,
  'role': 0.005,
  'interest': 0.005,
  'leader': 0.005,
  'statement': 0.005,
  'career': 0.005,
  'job': 0.005,
  'opportunity': 0.0045,
  'member': 0.004,
  'community': 0.004,
  'knowledge': 0.004,
  'development': 0.0035,
  'field': 0.0035,
  'work': 0.00325,
  'service': 0.003,
  'industry': 0.003,
  'experience': 0.003,
  'world': 0.0025,
  'access': 0.0025,
  'platform': 0.0025,
  'design': 0.002,
  'system': 0.002,
  'program': 0.002,
  'model': 0.002,
  'visit': 0.002,
  'share': 0.00175,
  'message': 0.00175,
  'help': 0.0016,
  'use': 0.0014,
  'research': 0.0013333333333333333,
  'faculty': 0.001,
  'change': 0.0008},
 4: {'talk': 0.021,
  'research': 0.016666666666666666,
  'proposal': 0.013,
  'analysis': 0.011,
  'presentation': 0.011,
  'technique': 0.009,
  'material': 0.009,
  'seminar': 0.009,
  'paper': 0.008,
  'method': 0.008,
  'study': 0.0075,
  'performance': 0.007,
  'structure': 0.007,
  'patient': 0.006,
  'health': 0.006,
  'stress': 0.006,
  'effect': 0.006,
  'discus': 0.006,
  'state': 0.005,
  'result': 0.005,
  'power': 0.005,
  'condition': 0.005,
  'trial': 0.005,
  'system': 0.004666666666666667,
  'model': 0.0045,
  'reminder': 0.004,
  'control': 0.004,
  'space': 0.004,
  'cover': 0.004,
  'focus': 0.004,
  'conference': 0.004,
  'interaction': 0.004,
  'factor': 0.004,
  'colleague': 0.004,
  'graph': 0.004,
  'work': 0.00375,
  'meeting': 0.0036666666666666666,
  'detail': 0.003,
  'problem': 0.0029999999999999996,
  'series': 0.0029999999999999996,
  'field': 0.0025,
  'process': 0.0025,
  'property': 0.0025,
  'speaker': 0.0025,
  'application': 0.002,
  'design': 0.002,
  'development': 0.002,
  'number': 0.0018333333333333333,
  'link': 0.00125,
  'time': 0.0005},
 5: {'forum': 0.072,
  'digest': 0.043,
  'lecture': 0.037,
  'class': 0.0365,
  'announcement': 0.029,
  'topic': 0.019,
  'question': 0.011333333333333334,
  'quiz': 0.01,
  'zoom': 0.01,
  'tomorrow': 0.009,
  'doubt': 0.009,
  'copy': 0.009,
  'regard': 0.0085,
  'let': 0.008,
  'submit': 0.008,
  'answer': 0.008,
  'meeting': 0.007666666666666666,
  'submission': 0.0075,
  'slide': 0.007,
  'sheet': 0.007,
  'paper': 0.0065,
  'today': 0.006,
  'client': 0.006,
  'watch': 0.006,
  'link': 0.00575,
  'note': 0.005333333333333333,
  'motor': 0.005,
  'video': 0.004,
  'solution': 0.004,
  'chemistry': 0.004,
  'roll': 0.004,
  'review': 0.004,
  'kind': 0.0035,
  'concern': 0.0035,
  'reminder': 0.003,
  'view': 0.0026666666666666666,
  'problem': 0.0023333333333333335,
  'thanks': 0.0023333333333333335,
  'student': 0.0021999999999999997,
  'discussion': 0.002,
  'word': 0.002,
  'time': 0.00175,
  'message': 0.00175,
  'contact': 0.0015,
  'number': 0.001,
  'change': 0.001,
  'use': 0.001,
  'request': 0.001,
  'date': 0.001,
  'email': 0.0008},
 6: {'campus': 0.02,
  'hostel': 0.02,
  'staff': 0.016,
  'situation': 0.013,
  'office': 0.012,
  'student': 0.011,
  'mess': 0.01,
  'company': 0.01,
  'room': 0.009,
  'survey': 0.008,
  'day': 0.007,
  'permission': 0.007,
  'cycle': 0.007,
  'person': 0.0065,
  'return': 0.006,
  'plan': 0.006,
  'month': 0.006,
  'measure': 0.006,
  'order': 0.006,
  'facility': 0.006,
  'security': 0.005,
  'attendance': 0.005,
  'bus': 0.005,
  'suggestion': 0.005,
  'safety': 0.005,
  'report': 0.005,
  'rule': 0.005,
  'period': 0.005,
  'employee': 0.005,
  'work': 0.00475,
  'home': 0.004,
  'activity': 0.0035,
  'lab': 0.0033333333333333335,
  'instruction': 0.003,
  'coordinator': 0.003,
  'internship': 0.003,
  'case': 0.00275,
  'schedule': 0.0025,
  'lot': 0.0025,
  'time': 0.002375,
  'institute': 0.0023333333333333335,
  'year': 0.00225,
  'member': 0.002,
  'help': 0.0018,
  'week': 0.0015,
  'faculty': 0.0015,
  'mail': 0.0012000000000000001,
  'number': 0.0011666666666666668,
  'request': 0.001,
  'change': 0.001},
 7: {'account': 0.034,
  'book': 0.032,
  'invitation': 0.025,
  'file': 0.022,
  'phone': 0.016,
  'drive': 0.015,
  'access': 0.013,
  'damage': 0.012,
  'video': 0.0115,
  'item': 0.011,
  'entry': 0.0095,
  'click': 0.009,
  'organizer': 0.009,
  'stop': 0.009,
  'page': 0.009,
  'address': 0.009,
  'meet': 0.008,
  'calendar': 0.008,
  'reply': 0.008,
  'article': 0.008,
  'line': 0.008,
  'source': 0.008,
  'logo': 0.008,
  'folder': 0.008,
  'receiving': 0.008,
  'comment': 0.008,
  'bee': 0.008,
  'response': 0.007,
  'image': 0.007,
  'detection': 0.006,
  'log': 0.006,
  'relief': 0.006,
  'theme': 0.006,
  'orientation': 0.006,
  'link': 0.005,
  'description': 0.005,
  'modify': 0.005,
  'verification': 0.005,
  'design': 0.004666666666666667,
  'notification': 0.0045,
  'week': 0.00425,
  'email': 0.004,
  'version': 0.003,
  'list': 0.0029999999999999996,
  'view': 0.0029999999999999996,
  'change': 0.0026,
  'share': 0.0025,
  'point': 0.0023333333333333335,
  'mail': 0.0016,
  'request': 0.0014},
 8: {'course': 0.178,
  'semester': 0.028,
  'fee': 0.019,
  'payment': 0.019,
  'registration': 0.014,
  'instructor': 0.013,
  'match': 0.013,
  'student': 0.0114,
  'preference': 0.01,
  'evaluation': 0.01,
  'phase': 0.009,
  'exam': 0.009,
  'slot': 0.007,
  'trademark': 0.007,
  'batch': 0.006,
  'module': 0.006,
  'recommendation': 0.006,
  'backlog': 0.006,
  'credit': 0.006,
  'approval': 0.006,
  'class': 0.0055,
  'note': 0.005,
  'drop': 0.005,
  'consent': 0.005,
  'catalog': 0.005,
  'faculty': 0.004,
  'manage': 0.004,
  'register': 0.0035,
  'schedule': 0.0035,
  'difficulty': 0.0035,
  'date': 0.003,
  'section': 0.003,
  'list': 0.0029999999999999996,
  'form': 0.00275,
  'query': 0.0025,
  'end': 0.0025,
  'property': 0.0025,
  'notification': 0.0025,
  'fill': 0.0025,
  'institute': 0.002,
  'deadline': 0.002,
  'concern': 0.002,
  'number': 0.0016666666666666668,
  'change': 0.0016,
  'detail': 0.0016,
  'week': 0.0015,
  'time': 0.00125,
  'email': 0.001,
  'mail': 0.001,
  'today': 0.001},
 9: {'mark': 0.026,
  'code': 0.018,
  'term': 0.016,
  'score': 0.015,
  'test': 0.013,
  'examination': 0.01,
  'case': 0.0095,
  'end': 0.008,
  'road': 0.008,
  'block': 0.008,
  'trouble': 0.007,
  'need': 0.007,
  'location': 0.007,
  'criterion': 0.006,
  'size': 0.006,
  'input': 0.006,
  'ability': 0.006,
  'unsubscribe': 0.006,
  'try': 0.006,
  'issue': 0.005,
  'approach': 0.005,
  'prepare': 0.005,
  'vehicle': 0.005,
  'rest': 0.005,
  'flood': 0.005,
  'soil': 0.005,
  'question': 0.004,
  'estimate': 0.004,
  'experiment': 0.004,
  'poverty': 0.004,
  'flight': 0.004,
  'decision': 0.004,
  'auto': 0.004,
  'dimension': 0.004,
  'component': 0.004,
  'distance': 0.004,
  'data': 0.0035,
  'practice': 0.003,
  'time': 0.002875,
  'version': 0.0025,
  'instruction': 0.0025,
  'difficulty': 0.0025,
  'lab': 0.0023333333333333335,
  'study': 0.002,
  'form': 0.00175,
  'email': 0.0016,
  'use': 0.0014,
  'detail': 0.0014,
  'number': 0.001,
  'week': 0.001},
 10: {'thing': 0.027,
  'way': 0.023,
  'type': 0.018,
  'life': 0.017,
  'people': 0.0145,
  'body': 0.013,
  'story': 0.013,
  'year': 0.009,
  'exercise': 0.009,
  'moment': 0.009,
  'mentor': 0.009,
  'hand': 0.009,
  'word': 0.008,
  'eye': 0.008,
  'mind': 0.008,
  'experience': 0.0075,
  'movement': 0.007,
  'joy': 0.007,
  'place': 0.007,
  'control': 0.006,
  'congratulation': 0.006,
  'woman': 0.006,
  'sentence': 0.006,
  'language': 0.006,
  'world': 0.005,
  'fact': 0.005,
  'school': 0.005,
  'night': 0.005,
  'challenge': 0.0045,
  'idea': 0.004,
  'lot': 0.004,
  'money': 0.004,
  'sense': 0.004,
  'step': 0.004,
  'medium': 0.004,
  'matter': 0.004,
  'head': 0.004,
  'day': 0.0036666666666666666,
  'person': 0.0035,
  'question': 0.0033333333333333335,
  'time': 0.003125,
  'help': 0.003,
  'practice': 0.003,
  'home': 0.003,
  'point': 0.0029999999999999996,
  'share': 0.00225,
  'work': 0.002,
  'today': 0.00175,
  'system': 0.0013333333333333333,
  'use': 0.0012000000000000001}}

"""##Code"""

def avg_embedding(data):

  # create the dict.
  x = data.keys()
  y = list(data.values())
  tokenizer = Tokenizer()
  tokenizer.fit_on_texts(x)
    
  # number of unique words in dict.
  print("Number of unique words in dictionary=", 
        len(tokenizer.word_index))
  print("Dictionary is = ", tokenizer.word_index)
    
  # download glove and unzip it in Notebook.
  #!wget http://nlp.stanford.edu/data/glove.6B.zip
  #!unzip glove*.zip
    
  # vocab: 'the': 1, mapping of words with
  # integers in seq. 1,2,3..
  # embedding: 1->dense vector
  def embedding_for_vocab(filepath, word_index,
                          embedding_dim):
      vocab_size = len(word_index) + 1
        
      # Adding again 1 because of reserved 0 index
      embedding_matrix_vocab = np.zeros((vocab_size,
                                        embedding_dim))
    
      with open(filepath, encoding="utf8") as f:
          for line in f:
              word, *vector = line.split()
              if word in word_index:
                  idx = word_index[word]
                  embedding_matrix_vocab[idx] = np.array(
                      vector, dtype=np.float32)[:embedding_dim]
    
      return embedding_matrix_vocab
    
    
  # matrix for vocab: word_index
  embedding_dim = gdim
  embedding_matrix_vocab = embedding_for_vocab(
      '/content/glove.6B.200d.txt', tokenizer.word_index,
    embedding_dim)
    
  # print("Dense vector for first word is => ",
  #       embedding_matrix_vocab[2])

  sum = np.zeros(gdim)
  for i in range(1, len(tokenizer.word_index)+1):
    sum += (y[i-1] * embedding_matrix_vocab[i])

  # print("Average of all word embeddings",
  #       sum/(len(tokenizer.word_index)+1))

  return embedding_matrix_vocab,sum/(len(tokenizer.word_index))

topic_embedds = []
topic_matrix = np.zeros((11,51,200))
i = 0
for listing in Tags_prob:
    topic_matrix[i],v = avg_embedding(Tags_prob[listing])
    topic_embedds.append(v)
    i += 1

def mail_avg_embedding(x):

  # create the dict.
  tokenizer = Tokenizer()
  tokenizer.fit_on_texts(x)
    
  # number of unique words in dict.
  # print("Number of unique words in dictionary=", 
  #       len(tokenizer.word_index))
  # print("Dictionary is = ", tokenizer.word_index)
    
  # download glove and unzip it in Notebook.
  #!wget http://nlp.stanford.edu/data/glove.6B.zip
  #!unzip glove*.zip
    
  # vocab: 'the': 1, mapping of words with
  # integers in seq. 1,2,3..
  # embedding: 1->dense vector
  def embedding_for_vocab(filepath, word_index,
                          embedding_dim):
      vocab_size = len(word_index) + 1
        
      # Adding again 1 because of reserved 0 index
      embedding_matrix_vocab = np.zeros((vocab_size,
                                        embedding_dim))
    
      with open(filepath, encoding="utf8") as f:
          for line in f:
              word, *vector = line.split()
              if word in word_index:
                  idx = word_index[word]
                  embedding_matrix_vocab[idx] = np.array(
                      vector, dtype=np.float32)[:embedding_dim]
    
      return embedding_matrix_vocab
    
    
  # matrix for vocab: word_index
  embedding_dim = gdim
  embedding_matrix_vocab = embedding_for_vocab(
      '/content/glove.6B.200d.txt', tokenizer.word_index,
    embedding_dim)
    
  # print("Dense vector for first word is => ",
  #       embeddin0g_matrix_vocab[2])
  sum = np.zeros(gdim)
  for i in range(len(tokenizer.word_index)+1):
    sum += embedding_matrix_vocab[i]

  # print("Average of all word embeddings",
  #       sum/(len(tokenizer.word_index)+1))

  return sum/(len(tokenizer.word_index)+1)

def compare_single_embeddings(u,v):
  #u = glove[x].numpy()
  cosine = np.dot(u,v)/(norm(u)*norm(v))
  return cosine

def cos_similarity(filename):
  x_test = preprocess_mail(filename)
  cos = []
  u = mail_avg_embedding(x_test)
  for v in topic_embedds:
    cosine = np.dot(u,v)/(norm(u)*norm(v))
    cos.append(cosine)
  #print(cos)
  topic = cos.index(max(cos))
  wcos = {}
  i = 1
  for word in list(Tags_prob[topic].keys())[:10]:
    val = compare_single_embeddings(topic_matrix[topic][i],u)
    wcos[word] = val
    i += 1
  top_4 = dict(sorted(wcos.items(), \
             key = operator.itemgetter(1)))
  return list(top_4.keys())[:4]

cos_similarity("/content/drive/MyDrive/BTP_TestSet_Mails/test8.txt")

cos_similarity("/content/drive/MyDrive/BTP_TestSet_Mails/test2.txt")

cos_similarity("/content/drive/MyDrive/BTP_TestSet_Mails/test13.txt")

"""#Evaluation"""

def model_prediction(text):
  x_test = preprocess(text)
  cos = []
  u = mail_avg_embedding(x_test)
  for v in topic_embedds:
    cosine = np.dot(u,v)/(norm(u)*norm(v))
    cos.append(cosine)
  #print(cos)
  topic = cos.index(max(cos))
  wcos = {}
  i = 1
  for word in list(Tags_prob[topic].keys())[:10]:
    val = compare_single_embeddings(topic_matrix[topic][i],u)
    wcos[word] = val
    i += 1
  top_4 = dict(sorted(wcos.items(), \
             key = operator.itemgetter(1)))
  print(list(top_4.keys())[:4])
  return list(top_4.keys())[:4]

test = []
for i in range(1, 101):
  filename = "/content/drive/MyDrive/BTP_TestSet_Mails/test" + str(i) + ".txt"
  with open(filename, "r") as f:
    text = f.read().strip().lower().replace('\n', '')
    test.append(text)

import pandas as pd

test_data_path = "/content/drive/MyDrive/BTP_Aishu/GoldSet_BTP - Sheet1.csv"
data = pd.read_csv(test_data_path)
data['Tags'] = data['Tags'].str.replace(" ", "")

data

class MailTester:
  def __init__(self, test_mails, test_data, model):
    self.test_mails = test_mails
    self.model = model
    self.test_data = test_data
    self.test()
  
  def test(self):
    correct_predictions = 0
    total_predictions = 0

    for index, row in self.test_data.iterrows():
        mail_body = self.test_mails[index]
        expected_tags = set(row['Tags'].split(','))
        predicted_tags = set(model_prediction(mail_body))#set(self.model.predict(mail_body))
        common_tags = set(expected_tags).intersection(predicted_tags)
        if len(common_tags) > 0:
          correct_predictions += 1
        total_predictions += 1

    accuracy = correct_predictions / total_predictions
    print(f"Accuracy: {accuracy}")

import numpy as np
from scipy.spatial.distance import cosine
from gensim.models import KeyedVectors
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np
from numpy.linalg import norm
import tensorflow as tf
import torch
import torchtext

class MailTester:
  def __init__(self, test_mails, test_data, model):
    self.test_mails = test_mails
    self.model = model
    self.test_data = test_data
  
  def test(self):
    correct_predictions = 0
    total_predictions = 0

    for index, row in self.test_data.iterrows():
        mail_body = self.test_mails[index]
        expected_tags = set(row['Tags'].split(','))
        predicted_tags = set(model_prediction(mail_body))#set(self.model.predict(mail_body))
        common_tags = set(expected_tags).intersection(predicted_tags)
        if len(common_tags) > 0:
          correct_predictions += 1
        total_predictions += 1

    accuracy = correct_predictions / total_predictions
    print(f"Accuracy: {accuracy}")
  
  def find_similar(self, list1, list2):
    glove_model = torchtext.vocab.GloVe(name="6B", dim=200)
    threshold = 0.9
    similar_words = []
    for word1 in list1:
        for word2 in list2:
            distance = cosine(glove_model[word1], glove_model[word2])
            if distance > threshold:
                similar_words.append((word1, word2))
    return similar_words

  def test_sim(self):
    correct_predictions = 0
    total_predictions = 0
    for index, row in self.test_data.iterrows():
        mail_body = self.test_mails[index]
        expected_tags = set(row['Tags'].split(','))
        predicted_tags = set(model_prediction(mail_body))
        common_tags = self.find_similar(expected_tags, predicted_tags)
        if len(common_tags) > 0:
          correct_predictions += 1
        total_predictions += 1

    accuracy = correct_predictions / total_predictions
    print(f"Accuracy: {accuracy}")

tester = MailTester(test, data, None)

tester.test_sim()

tester.test()

